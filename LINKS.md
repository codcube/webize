# WHAT

fix the web in post-production. some suggest we abandon it - we'd rather create the [web we want](https://webwewant.org/) via format and protocol bridging to tools of the desired capabilities

# WHY

formative-era browsers display blank pages in the era of "single-page apps" while newer browsers execute remote code or too suffer the [blank-page](https://docs.google.com/presentation/d/120CBI6_gIGqKflXoGp8UMpge1OJ7hfHNNl7JLARUT_o/edit#slide=id.p) problem. default browser configuration - a privacy disaster instantly and silently reporting data to third parties as soon as a page is loaded - is increasingly the only state of affairs due to unavailability of plugins like [uBlock Origin](https://github.com/gorhill/uBlock) on popular mobile and embedded-webview browsers. browsers that aren't privacy messes riddled with surveillytics eager to display a blank page would be nice, but if business motives of the large browser vendors - coincidentally the biggest tracking companies themselves - haven't aligned to give users this basic functionality save for third-party plugins at risk of breakage on desktop browsers and unavailable on mobile, it may not be coming. [Palemoon](https://forum.palemoon.org/) has shown that lone-rangers can maintain a browser fork, but this requires individuals of exceptional motivation of which there are apparently only a few on the planet, and relying on their continued interest is hardly a safe bet.

on servers, most don't support [content negotiation](https://www.w3.org/DesignIssues/Conneg) or globally-identified graph data, only offering ad-hoc site-specific HTML/JSON/Protobuf subformats, making [supplying your own interface](https://donnywinston.com/posts/can-i-go-home-now/), browser or cross-site data integrations difficult, tossing notions of low/no-code [serendipitous](https://noeldemartin.com/blog/interoperable-serendipity) mashups & data-reuse to the wayside while begging the developer to craft bespoke integrations involving site-specific APIs, account registrations and API keys, glued together by fiddling around writing code depending on site-specific API-client libraries. nothing says 'browse content' like 'do a bunch of tedious stuff including write custom code involving dependencies not in the distro package manager'. that's [considered normal](https://doriantaylor.com/the-symbol-management-problem#:~:text=age%20of%20APIs) these days - snowflake APIs demanding special treatment and the vast make-work project of [one-off](https://subconscious.substack.com/p/composability-with-other-tools) integrations.

# HOW

present a better server to the client via proxy. explicit/transparent/URI-rewrite modes are supported for wide compatibility including [non-HTTPS](http://michael.orlitzky.com/articles/lets_not_encrypt.xhtml) browsers and cert-pinned/guest-mode kiosks. a config for [Squid](http://www.squid-cache.org/) is included as a HTTPS frontend (pure-ruby SSL options coming as soon as i RTFM) while backend handlers are spun up as needed. servers are made [less bad](http://suckless.org/philosophy/), bestowed with content-negotiation, data mapped to a [universal](https://www.geoffreylitt.com/wildcard/salon2020/#expose-a-universal-data-structure) [model](https://www.w3.org/RDF/) available in a multitude of formats. clients need to know just [one API, HTTP](https://ruben.verborgh.org/blog/2013/11/29/the-lie-of-the-api/). blank pages are swapped with renderings of data found in any provided HTML/JSON(LD)/Microformats/RDFa. we're obsessed with finding all the data on offer, so in addition to the formats afforded by Ruby's RDF library, mappers exist for a variety of non-RDF formats like [Atom/RSS](https://karl-voit.at/2020/10/23/avoid-web-forums/), e-mail and miscellaneous stuff you may find on a filesystem. the proxy adds a graph cache [to the hierarchy](https://gist.github.com/paniq/bf5b291949be14771344b19a38f042c0), facilitating offline scenarios and [automatic archiving](https://beepb00p.xyz/sad-infra.html)

whether mapping the modern app-web to HTML for [dillo](https://www.dillo.org/)/[elinks](http://elinks.or.cz/)/[eww](https://www.gnu.org/software/emacs/manual/html_mono/eww.html)/[links](http://links.twibright.com/)/[lynx](https://lynx.browser.org/)/[w3m](http://w3m.sourceforge.net/), Gemtext for [Geopard](https://ranfdev.com/projects/geopard/)/[Ladybird](https://awesomekling.github.io/Ladybird-a-new-cross-platform-browser-project/)/[Lagrange](https://gmi.skyjake.fi/lagrange/), or [Turtle](https://en.wikipedia.org/wiki/Turtle_(syntax)) for [Solid-compliant](https://gitter.im/solid/specification) [data browsers](https://github.com/solid/data-kitchen) and [user agents](https://syntropize.com/docs/#/Synopsis/), your interface is [user-supplied](https://www.geoffreylitt.com/2021/03/05/bring-your-own-client.html) from a codebase [you control](https://www.gnu.org/philosophy/keep-control-of-your-computing.en.html#content). since user freedom and autonomy is paramount, one may opt to run 3rd-party JS in the original UI - in this case cyan entries in the log are often fresh trackingware startups you didn't know about yet. the imagination of the [surveillance economy](https://news.harvard.edu/gazette/story/2019/03/harvard-professor-says-surveillance-capitalism-is-undermining-democracy/) to think up new tricks is seemingly unbounded, and you may find this a useful toolkit to begin to respond, by never running Javascript again, and reducing or eliminating requests that make it out to the net and its cloud marketplaces that buy and sell your data. when deprived of developer tools and plugins on a mobile OS, transparent-mode is a way to have desktop-grade [visibility](https://github.com/OxfordHCC/tracker-control-android) into what's going on, and control it at an instrumentable/scriptable proxy layer, while recording the data so it's not trapped in an app that won't run on the next version of Android or when VC funding pulls the plug.

we're intent on doing things with as minimal a set of dependencies, abstractions and lines of code as possible, because there's only so much an unpaid maintainer can handle, third-party library churn introduces breakage, etc. this library is an experimental testbed for explorations on this trajectory, as we seek to retain malleability for project evolution for [tracking of changing specs](https://socialhub.activitypub.rocks/) and moving towards compatibility with [other projects](https://braid.org/). the main abstraction we've introduced is a Resource class, derived from a class in the RDF library representing the [resource's identifier](https://datatracker.ietf.org/doc/html/rfc1630). it's paired with an [environment](https://www.rubydoc.info/gems/rack/Rack/Request/Env) - transient request-data guiding codepath selections. input/output 'webizers' are defined as parsers/serializers per RDF library convention. compatibility with these abstractions is a key part of enabling integration with the long-tail of filesystem, RDF and web libraries/tooling in Ruby/Java/JRuby/Clojure, Ruby-to-WASM compilation backends for browser deployment and the shell.

we haven't required third-party graph databases which have proven a hurdle to adoption of RDF-based solutions outside of certain well-resourced situations like massive dragnet marketing/telemetry/surveillytics operations, intelligence agencies, or institutional repositories with grant or university backed sysadmin teams. aside from dev/ops maintenance/configuration demands plus cloud usage fees if open source, or SAAS rental fees if hosted/managed, there's a resource budget even when self-hosted and local-first. our RAM budget is a slice of a 512M raspi, ~1G vintage laptop, or ~2G netbook/tablet's capacity. Java graph databases usually failed to launch due to not having enough RAM - that's what led us to finding a way to work without them. while we're too broke to purchase beastly Apple computers or rent servers suitable for beastly Java stacks (and would rather not just to access our own data), we're still awash in underutilized ambient computing power with a small handful of mostly-idle lowend devices, which, if Android, have everything-but-root POSIX/UNIXy userspace facilities available via [Termux](https://f-droid.org/en/packages/com.termux/). as voracious blog readers in dozens of chat channels who do lots of web browsing, we accumulate ~2K üê¢s a day, each with ~50-5000 triples. a few million triples a month - well within what we can query on our own devices. the HTTP daemon and kernel fs populated with üê¢s *is* our sole graph database, after voluminous dogfooding of aggregation/synchronization/news/chat/webmail scenarios. there are lightweight keyval stores and [RDF::Repository](https://www.google.com/search?q="RDF%3A%3ARepository"+site%3Agithub.com#) backends we haven't needed to involve. if so, ideally it would be something where we get something besides basic storage out of it, like maybe taking a SQLite backend and making it work on a [CRDTSQL](https://github.com/vlcn-io/cr-sqlite), or saving our RDF as JSON-LD to a JSON store with a distributed persistence story for us like maybe [Hypercore](https://github.com/holepunchto/hypercore). ultimately we're KISS principle types, and are decades into this and still working on getting localhost shored up and rsync has served us well for replication, so please let us know what you come up with.

efforts have been focused on supporting 'basic browsing' with nose-following hints and references, without a hypercomplex Chromium/Mozilla useragent, through good graph-data, extremely simple markup (and no javascripts), and HTTP page-pointer metadata. simultaneously we're trying to eliminate the need to write SPARQL or GraphQL (writing queries is way less accessible than browsing, and introduces db-engine overhead discussed above) by combining a good basic browsing experience with lightweight filtering and temporal-narrowing addressable at URI-level rather than constructing a complex query string and sending it off to someone else's server. this is made easier since we have full control of the graph-data structure and URI mappings when data isn't already delivered to us as RDF (most of the time) while extant RDF is subject to an indexing pass. if [Linked Data Fragments](https://linkeddatafragments.org/concept/) index endpoints or [the "Martynas approach"](https://nitter.net/namedgraph) of generated SPARQL take off in adoption we may rethink this approach to be more compatible with what's going on and take advantage of cool new libraries or look like we're a relevant project to attract users or consulting gigs.

working around mutual disinterest with industry is a goal - our applications must hit /dev/null due to highly-optimized AI filters. take formidable competition from full-suite CS grads from reputable instutions (we barely read manpages, and our Knuth books are collecting dust), add our stance on artificial-scarcity and secrecy or more specifically intellectual property, proprietary platforms, non-disclosure agreements and security clearances, a history of job-quitting due to burnout and distaste for the "product", lengthy employment gaps, no credentials, certifications, degrees, industry experience, LinkedIn accts, familiarity with JS frameworks or buzzwords-du-jour. the AI definitely made the right choice, given our goal is crash the company from the inside (while getting a paycheck), giving autonomy back to the users to no longer depend on rented access to a remote platform and then the platform can be shut down. however, the [TODO](TODO.md) list is long, and to hire someone to chip away at it we'd need money to pay a developer, so hopefully they hire us anyway and we'll learn to suck it up and stomach the disgust. this assumes "get paid to do open source" is out of the question near and mid-term considering we haven't gotten a star or PR or bug report yet, so a cadre of sponsors is a long ways off if even plausible for this script-kiddie stuff.

working around mutual disinterest with Academia is a goal - it's arguable if there's even a good implementation of CMU [lifelog](https://dl.acm.org/doi/pdf/10.1145/381854.381893) papers from the 1980s, yet we keep getting more papers instead of better implementations of stuff written about long ago. I've heard the academy considers robust implementations the job of industry - but industry wants rent-seeking, subscription fees, lock-in and outmigration friction, creepy user-data-monetization, advertising, dark-patterns, and enshittification.. so you can begin to see why we just live in the hood and never spend money except on rent and food, so we don't have to create the crap we don't want for some tech company, or write the papers we don't need for some ivory-tower dwellers..

perhaps we need a new toplevel category of human activity, alongside academy and industry, that finds and funds people more motivated and skilled than ourselves to make nice, open, unenshittified implementations of stuff described in published papers so it can't surface later in a patent due to the documented and demonstrated prior art. and we probably need to publish a bit more outside of obscure markdown files, especially when it comes to stuff like the IRC replacement, lest lawyers at Discord or MS Teams try to sue us into oblivion for infringements on ideas they filed first. suppose this new toplevel category contains 'Shadow IT' and 'hacker stuff'. there's still plenty of dissensus and duplicated effort but at least we mostly agree on the 'what', if not the 'how' - from fellow hacker angles there's opinions that [Ruby](https://rubyreferences.github.io/rubychanges/) isn't a [serious-business](https://avdi.codes/what-is-the-ruby-legacy/#div-comment-16410) language like Rust, and our opinions that coders are working on the "wrong things" in the graph space. behold the variety of [proprietary](https://www.inrupt.com/products/enterprise-solid-server) graph-store platforms you can subscribe to which are ultimatelly re-skinned [neo4j](https://en.wikipedia.org/wiki/Neo4j) or [Virtuoso](https://en.wikipedia.org/wiki/Virtuoso_Universal_Server) and a bunch of marketing fluff, or rent access to fresh formerly-FOSS [acqui-kills](https://en.wikipedia.org/wiki/Amazon_Neptune#History) by Tier-1 cloud overlords.

as long as people are still using [Facebook](https://stallman.org/facebook.html), [Slack](https://news.ycombinator.com/item?id=18893212#18900853), [Discord](https://stallman.org/discord.html), or anything that isn't using open protocols and requires the use of a closed-source client, there's work to be done to reduce the friction of self-hosted linked-data, advocate for adoption of mixnet/gossip/store&forward protocols, support and improve end-user data sovereignty and nomadic identity and make more realistic and easy the cold-turkeying of [megabrowsers](https://drewdevault.com/2020/08/13/Web-browsers-need-to-stop.html) and online platforms/apps, while paving the way to a mostly-blockchain-free updated return to the USENET model of discourse and commerce. realistically a 486, IRC client, curl and a few sed/awk scripts are good enough for 90% of what we regularly do, we're just trying to go beyond this to evolve and keep our minds from going idle. wouldn't it be cool to no longer need a terminal emulator, a shell, grep and emacs, and have something as useful and flexible inside a lightweight networked data browser written in some Wayland UI toolkit usable from a cheap touchscreen tablet running [Alpine](https://alpinelinux.org/)? the Ruby [Async](https://github.com/socketry/async) and [RDF](https://ruby-rdf.github.io/) libraries are really good and underutilized and we hope to make something half as good as the library code it's running atop.

ideally the layperson can figure out how to launch their web server (without having to configure it first) and ctrl-C it when done, and not need to abstract their entire userspace (or multiple userspaces/VMs, orchestrated) with tools like Docker/Kubernetes/Terraform. welcome to the [user-centric](https://rbs.io/2019/05/a-revolution-in-your-pocket/), decentralized, human-scale edge web where git, [Tailscale](https://tailscale.com/blog/stuck-opening-the-socket/), the up-arrow and ctrl-C ought to be enough for most anyone. if you *want* to experiment with these things - say instant deployments of code updates to all your devices or advanced indexing capabilities with a SQLite backed graph DB - the codebase is designed to be evolvable and interoperable.

# WHERE

it's [your data](https://www.youtube.com/watch?v=-RoINZt-0DQ), and finding what you're looking for should be easy, even if your internet is down or you don't have [cloud](https://martin.kleppmann.com/2021/04/14/goodbye-gpl.html#the-enemy-has-changed) accounts, so on [localhost](http://localhost/) time-ordered data is made searchable by lightweight and venerable [find](https://www.gnu.org/software/findutils/manual/html_mono/find.html), [glob](https://en.wikipedia.org/wiki/Glob_(programming)) and [grep](https://www.gnu.org/software/grep/manual/grep.html). for more complicated queries, one can write [SPARQL](https://github.com/ruby-rdf/sparql) as the store comprises a [URI space](https://www.w3.org/DesignIssues/Axioms.html#uri) of RDF graph data. with Turtle files the [offline-first](https://offlinefirst.org/) / [local-first](https://www.inkandswitch.com/local-first.html) source of state, synchronization between devices can be handled by underlying file distribution tools such as [git](gemini://gemini.circumlunar.space/~solderpunk/gemlog/low-budget-p2p-content-distribution-with-git.gmi), [nncp](https://www.complete.org/nncp/), [scp](https://github.com/openssh/openssh-portable/blob/master/scp.c), [rsync](https://wiki.archlinux.org/index.php/Rsync) or [syncthing](https://syncthing.net/), at a higher-level by streaming RDF triples to other devices via [CRDTs](https://openengiadina.gitlab.io/dmc/) or [gossip networks](https://github.com/libp2p/specs/blob/master/pubsub/gossipsub/gossipsub-v1.1.md), or accessing remote nodes directly via HTTP services running on your personal [LAN](https://www.defined.net/nebula/)

# WHEN

in theory, this project can go away once clients and servers are [privacy respecting](https://privacypatterns.org/patterns/) and standards compliant in read/write APIs and formats. in reality, we've seen the reduction in user agency and nixing of generic access modes ([protocols](https://venkatesh-rao.gitbook.io/summer-of-protocols/) and formats, not platforms and products) in favor of vendor-controlled mobile and web apps, backed by "exciting" tech on (almost always remote) servers cultivating rented access to a small handful of proprietary hosting/API-platforms. basic GET requests are swapped for site-specific GRAPHQL queries - often via non-HTTP protocols like gRPC lacking mature and ubiquitous proxy tooling - and site-specific binary wire-formats with protobuf definitions as proprietary code unavailable for inspection or 3rd-party client code generation, while we don't know the queries since theyre referred to with the shortcut of an opaque hash. proprietary platforms continue to iterate on the inscrutable black-box dumb-terminal model they've loved selling since the 1960s.

# WHO

IX or poka on EFNet/Rizon (eventually OFTC/Libera once our planned credential-capable IRC bridge exists) chat. msg on IRC to notify if you've emailed the git address or created a bug-report/issue/PR on an online git mirror as those accounts have solely been for public backups/clone-points so far
